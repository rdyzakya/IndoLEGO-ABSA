{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../interim/interim_1/tech_test.txt\"\n",
    "\n",
    "with open(path,'r') as reader:\n",
    "    data = reader.read().strip().split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gab S-ORG\\nappears O\\nto O\\nbe O\\nlosing O\\ninvestors O\\nafter O\\nPittsburgh S-LOC\\nshooting O',\n",
       " 'Gab S-ORG\\n, O\\na O\\nsocial O\\nmedia O\\nplatform O\\npopular O\\nwith O\\nfar-right O\\nextremists O\\n, O\\nappears O\\nto O\\nhave O\\nlost O\\nmore O\\nthan O\\nthree O\\ndozen O\\nsmall O\\ninvestors O\\nin O\\nthe O\\nfour O\\ndays O\\nsince O\\na O\\nman O\\nposted O\\non O\\nthe O\\nsite O\\n, O\\n\" O\\nScrew O\\nyour O\\noptics O\\n, O\\nI O\\n\\'m O\\ngoing O\\nin O\\n, O\\n\" O\\nand O\\nthen O\\nallegedlyburst O\\ninto O\\na O\\nPittsburgh S-LOC\\nsynagogue O\\nand O\\nopened O\\nfire O\\n, O\\nkilling O\\n11 O\\npeople O\\nand O\\ninjuring O\\nsix O\\nothers O\\n. O']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    line = data[i].strip()\n",
    "    splitted_line = line.split('\\n')\n",
    "    result_line = []\n",
    "    for j,token_bio_tag in enumerate(splitted_line):\n",
    "        try:\n",
    "            token, bio_tag = token_bio_tag.split()\n",
    "        except Exception as e:\n",
    "            print(token_bio_tag)\n",
    "            print(line)\n",
    "            print(j)\n",
    "            print(splitted_line[24:26])\n",
    "            raise e\n",
    "        bio_tag = bio_tag.replace(\"S-\",\"B-\")\n",
    "        bio_tag = bio_tag.replace(\"E-\",\"I-\")\n",
    "        result_line.append(f\"{bio_tag}\\t{token}\")\n",
    "    result_line = '\\n'.join(result_line)\n",
    "    data[i] = result_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG\\tGab\\nO\\tappears\\nO\\tto\\nO\\tbe\\nO\\tlosing\\nO\\tinvestors\\nO\\tafter\\nB-LOC\\tPittsburgh\\nO\\tshooting',\n",
       " 'B-ORG\\tGab\\nO\\t,\\nO\\ta\\nO\\tsocial\\nO\\tmedia\\nO\\tplatform\\nO\\tpopular\\nO\\twith\\nO\\tfar-right\\nO\\textremists\\nO\\t,\\nO\\tappears\\nO\\tto\\nO\\thave\\nO\\tlost\\nO\\tmore\\nO\\tthan\\nO\\tthree\\nO\\tdozen\\nO\\tsmall\\nO\\tinvestors\\nO\\tin\\nO\\tthe\\nO\\tfour\\nO\\tdays\\nO\\tsince\\nO\\ta\\nO\\tman\\nO\\tposted\\nO\\ton\\nO\\tthe\\nO\\tsite\\nO\\t,\\nO\\t\"\\nO\\tScrew\\nO\\tyour\\nO\\toptics\\nO\\t,\\nO\\tI\\nO\\t\\'m\\nO\\tgoing\\nO\\tin\\nO\\t,\\nO\\t\"\\nO\\tand\\nO\\tthen\\nO\\tallegedlyburst\\nO\\tinto\\nO\\ta\\nB-LOC\\tPittsburgh\\nO\\tsynagogue\\nO\\tand\\nO\\topened\\nO\\tfire\\nO\\t,\\nO\\tkilling\\nO\\t11\\nO\\tpeople\\nO\\tand\\nO\\tinjuring\\nO\\tsix\\nO\\tothers\\nO\\t.',\n",
       " 'O\\tIn\\nO\\tthe\\nO\\tdays\\nO\\tsince\\nB-ORG\\tGab\\nO\\trose\\nO\\tto\\nO\\tnational\\nO\\tprominence\\nO\\tbecause\\nO\\tof\\nO\\tthe\\nO\\tviolent\\nO\\tand\\nB-MISC\\tanti-Semitic\\nO\\tpostings\\nO\\tmade\\nO\\tby\\nO\\taccused\\nO\\tshooter\\nB-PER\\tRobert\\nI-PER\\tBowers\\nO\\t,\\nO\\tthe\\nO\\tsite\\nO\\twas\\nO\\ttaken\\nO\\tdown\\nO\\t,\\nO\\tand\\nO\\ta\\nO\\tcount\\nO\\tof\\nO\\tits\\nO\\tinvestors\\nO\\ton\\nO\\ta\\nO\\tcrowdfunding\\nO\\tpage\\nO\\thas\\nO\\tslowly\\nO\\tdeclined\\nO\\t.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(line):\n",
    "    splitted_line = line.split('\\n')\n",
    "    text = []\n",
    "    named_entity = {}\n",
    "    prev_bio_tag = None\n",
    "    current_named_entity = []\n",
    "    for bio_tag_token in splitted_line:\n",
    "        bio_tag, token = bio_tag_token.split('\\t')\n",
    "        text.append(token)\n",
    "\n",
    "        # 1. if bio tag is B\n",
    "        #   1.1. prev tag is None\n",
    "        #   1.2. prev tag is O\n",
    "        #   1.3. prev tag is B\n",
    "        #       1.3.1. prev tag label is same\n",
    "        #       1.3.2. prev tag label is different\n",
    "        #   1.4. prev tag is I\n",
    "        #       1.4.1. prev tag label is same\n",
    "        #       1.4.2. prev tag label is different\n",
    "        # 2. if bio tag is I\n",
    "        #   2.1. prev tag is None\n",
    "        #   2.2. prev tag is O\n",
    "        #   2.3. prev tag is B\n",
    "        #       2.3.1. prev tag label is same\n",
    "        #       2.3.2. prev tag label is different\n",
    "        #   2.4. prev tag is I\n",
    "        #       2.4.1. prev tag label is same\n",
    "        #       2.4.2. prev tag label is different\n",
    "        # 3. if bio tag is O\n",
    "        #   3.1. prev tag is None\n",
    "        #   3.2. prev tag is O\n",
    "        #   3.3. prev tag is B\n",
    "        #   3.4. prev tag is I\n",
    "        if bio_tag.startswith(\"B-\"):\n",
    "            if prev_bio_tag == None:\n",
    "                # Append token\n",
    "                current_named_entity.append(token)\n",
    "            elif prev_bio_tag == 'O':\n",
    "                # Append token\n",
    "                current_named_entity.append(token)\n",
    "            elif prev_bio_tag.startswith(\"B-\"):\n",
    "                tag_label = bio_tag[2:]\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if tag_label == prev_tag_label:\n",
    "                    if not prev_tag_label in named_entity.keys():\n",
    "                        named_entity[prev_tag_label] = []\n",
    "                    named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                    current_named_entity = [token]\n",
    "                else:\n",
    "                    if not prev_tag_label in named_entity.keys():\n",
    "                        named_entity[prev_tag_label] = []\n",
    "                    named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                    current_named_entity = [token]\n",
    "            elif prev_bio_tag.startswith(\"I-\"):\n",
    "                tag_label = bio_tag[2:]\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if tag_label == prev_tag_label:\n",
    "                    if not prev_tag_label in named_entity.keys():\n",
    "                        named_entity[prev_tag_label] = []\n",
    "                    named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                    current_named_entity = [token]\n",
    "                else:\n",
    "                    if not prev_tag_label in named_entity.keys():\n",
    "                        named_entity[prev_tag_label] = []\n",
    "                    named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                    current_named_entity = [token]\n",
    "        elif bio_tag.startswith(\"I-\"):\n",
    "            if prev_bio_tag == None:\n",
    "                raise Exception(f\"I token cannot begin a named entity phrase | line : {line}\")\n",
    "            elif prev_bio_tag == 'O':\n",
    "                raise Exception(f\"I token cannot begin a named entity phrase | line : {line}\")\n",
    "            elif prev_bio_tag.startswith(\"B-\"):\n",
    "                tag_label = bio_tag[2:]\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if tag_label == prev_tag_label:\n",
    "                    # Append token\n",
    "                    current_named_entity.append(token)\n",
    "                else:\n",
    "                    raise Exception(f\"I token cannot align with B token with different label | line : {line}\")\n",
    "            elif prev_bio_tag.startswith(\"I-\"):\n",
    "                tag_label = bio_tag[2:]\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if tag_label == prev_tag_label:\n",
    "                    # Append token\n",
    "                    current_named_entity.append(token)\n",
    "                else:\n",
    "                    raise Exception(f\"I token cannot align with I token with different label | line : {line}\")\n",
    "        elif bio_tag == 'O':\n",
    "            if prev_bio_tag == None:\n",
    "                pass\n",
    "            elif prev_bio_tag == 'O':\n",
    "                pass\n",
    "            elif prev_bio_tag.startswith(\"B-\"):\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if not prev_tag_label in named_entity.keys():\n",
    "                    named_entity[prev_tag_label] = []\n",
    "                named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                current_named_entity = []\n",
    "            elif prev_bio_tag.startswith(\"I-\"):\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if not prev_tag_label in named_entity.keys():\n",
    "                    named_entity[prev_tag_label] = []\n",
    "                named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                current_named_entity = []\n",
    "        else:\n",
    "            raise Exception(f\"Unknown tag {bio_tag}\")\n",
    "        prev_bio_tag = bio_tag\n",
    "    \n",
    "    if prev_bio_tag != 'O': # last token\n",
    "        prev_tag_label = prev_bio_tag[2:]\n",
    "        if not prev_tag_label in named_entity.keys():\n",
    "            named_entity[prev_tag_label] = []\n",
    "        named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "        current_named_entity = []\n",
    "    \n",
    "    return ' '.join(text), named_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [preprocess_line(line) for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gab appears to be losing investors after Pittsburgh shooting',\n",
       "  {'ORG': ['Gab'], 'LOC': ['Pittsburgh']}),\n",
       " ('Gab , a social media platform popular with far-right extremists , appears to have lost more than three dozen small investors in the four days since a man posted on the site , \" Screw your optics , I \\'m going in , \" and then allegedlyburst into a Pittsburgh synagogue and opened fire , killing 11 people and injuring six others .',\n",
       "  {'ORG': ['Gab'], 'LOC': ['Pittsburgh']}),\n",
       " ('In the days since Gab rose to national prominence because of the violent and anti-Semitic postings made by accused shooter Robert Bowers , the site was taken down , and a count of its investors on a crowdfunding page has slowly declined .',\n",
       "  {'ORG': ['Gab'], 'MISC': ['anti-Semitic'], 'PER': ['Robert Bowers']}),\n",
       " ('On the website StartEngine.com , Gab is soliciting investments of at least $ 252 for \" $ 4/share of Class B Non-Voting Common Stock deliverable in token form ( the \\' GAB Tokens \\' ) . \"',\n",
       "  {'ORG': ['Gab', 'GAB']}),\n",
       " ('A cached image of the page shows the fundraising drive , which began on Sept. 19 , had at least $ 1,068,484.87 from 1,279 investors as of Saturday night.',\n",
       "  {})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = {}\n",
    "for el in data:\n",
    "    text, named_entity = el\n",
    "    for k,v in named_entity.items():\n",
    "        if k not in value_counts.keys():\n",
    "            value_counts[k] = 0\n",
    "        value_counts[k] += len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORG': 875, 'LOC': 489, 'MISC': 365, 'PER': 1094}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_map = {\n",
    "    \"ORG\" : \"Organization\",\n",
    "    \"LOC\" : \"Location\",\n",
    "    \"MISC\" : \"Miscellaneous\",\n",
    "    \"PER\" : \"Person\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = \"<extra_id_X>\"\n",
    "for i in range(len(data)):\n",
    "    inputs = f\"Extract NER with format >> entity : <extra_id_0>, entity_type : <extra_id_1> | {data[i][0]}\"\n",
    "    if len(data[i][1]) > 0:\n",
    "        out = []\n",
    "        cnt = 0\n",
    "        for k,v in data[i][1].items():\n",
    "            for v2 in v:\n",
    "                cnt = cnt%100\n",
    "                tup = f\"{mask.replace('X',str(cnt))} {v2} {mask.replace('X',str(cnt+1))} {entity_map[k].lower()}\"\n",
    "                cnt += 2\n",
    "                out.append(tup)\n",
    "        out = \" ; \".join(out)\n",
    "    else:\n",
    "        out = \"NULL\"\n",
    "    data[i] = {\n",
    "        \"input\" : inputs,\n",
    "        \"output\" : out\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Extract NER with format >> entity : <extra_id_0>, entity_type : <extra_id_1> | Gab appears to be losing investors after Pittsburgh shooting',\n",
       " 'output': '<extra_id_0> Gab <extra_id_1> organization ; <extra_id_2> Pittsburgh <extra_id_3> location'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../interim/interim_2/tech.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5045f1ed516028e6ba3c78ae58e34f2955ee8afe7e35fc1835a968676e80520"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
