{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = os.listdir(\"./output\")\n",
    "last_ckpt = max(ckpt, key=lambda x: int(x.split('-')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "last_state_path = \"./output/\" + last_ckpt + \"/trainer_state.json\"\n",
    "with open(last_state_path, 'r') as fp:\n",
    "    last_state = json.load(fp)\n",
    "\n",
    "best_state_path = last_state[\"best_model_checkpoint\"]\n",
    "model_name_or_path = best_state_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m13519061/anaconda3/envs/absa/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "encoding_args = {\n",
    "    \"max_length\" : max_length,\n",
    "    \"padding\" : True,\n",
    "    \"truncation\" : True,\n",
    "    \"return_tensors\" : \"pt\"\n",
    "}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../src\")\n",
    "import data_utils\n",
    "from evaluation import compute_metrics, summary_score\n",
    "\n",
    "catch_answer_fn = getattr(data_utils.AnswerCatcher(),\"lego_absa\")\n",
    "decoding_args = {\n",
    "    \"skip_special_tokens\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def generate_predictions(model,tokenizer,data,device=torch.device(\"cuda:0\"),decoding_args:Dict={}) -> List[str]:\n",
    "    # Predict\n",
    "    model = model\n",
    "    tokenizer = tokenizer\n",
    "    tensor_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(data):\n",
    "            input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "            tensor_predictions.extend(model.generate(input_ids=input_ids, pad_token_id=tokenizer.pad_token_id,eos_token_id=tokenizer.eos_token_id,max_length=max_length).cpu())\n",
    "            input_ids = input_ids.cpu()\n",
    "            # attention_mask = attention_mask.cpu()\n",
    "    tensor_predictions = [[token for token in row if token != -100] for row in tensor_predictions]\n",
    "    predictions = tokenizer.batch_decode(tensor_predictions,**decoding_args)\n",
    "    predictions = [el for el in predictions]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1081/1081 [00:00<00:00, 22113.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "test_path = \"../../../data/absa/en/zhang/interim/interim_2/rest1516/test.txt\"\n",
    "\n",
    "test_tasks = [\n",
    "    {\n",
    "        \"paradigm\" : \"extraction\",\n",
    "        \"se_order\" : \"oasc\",\n",
    "        \"prompt\" : \"lego_absa\",\n",
    "        \"answer\" : \"lego_absa\"\n",
    "    }\n",
    "]\n",
    "\n",
    "test = data_utils.read_data(test_path)\n",
    "test_ds = data_utils.data_gen(data=test, nt_se_order=\"acso\", tasks=test_tasks, n_fold=1, algo=\"round_robin\", shuffle=False)\n",
    "test_ds = Dataset.from_list(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1080/1080 [06:47<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "inputs = test_ds[\"input\"]\n",
    "str_preds = generate_predictions(model, tokenizer, inputs, device, decoding_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import json\n",
    "test_and_preds = []\n",
    "for i in range(len(test_ds)):\n",
    "    row = deepcopy(test_ds[i])\n",
    "    row.update({\n",
    "        \"preds\" : str_preds[i]\n",
    "    })\n",
    "    test_and_preds.append(row)\n",
    "\n",
    "with open(\"test_and_preds.json\", 'w') as fp:\n",
    "    json.dump(test_and_preds, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_preds = [el.replace(\"</s>\",'').replace(\"<pad>\",'') for el in str_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "oasc_ext_preds = [catch_answer_fn(out, \"oasc\", text) for out, text in zip(str_preds, test_ds[\"input\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [catch_answer_fn(out, \"oasc\", text) for out, text in zip(test_ds[\"output\"], test_ds[\"input\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.48085373509102325,\n",
       " 'precision': 0.4916330063473745,\n",
       " 'f1_score': 0.48618363073310605}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summary_score(oasc_ext_preds,targets)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"summary_score.json\", 'w') as fp:\n",
    "    json.dump(summary, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
